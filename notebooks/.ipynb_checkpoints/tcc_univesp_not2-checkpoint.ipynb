{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trablho de Conclusão de Curso - UNIVESP - 1S/2025- Notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código: tcc530-sala-002grupo-002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Packges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packges Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2593,
     "status": "ok",
     "timestamp": 1739237469924,
     "user": {
      "displayName": "Felipe Silva",
      "userId": "04798968727763788783"
     },
     "user_tz": 180
    },
    "id": "VK3zJVi_mmB2"
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "# Bibliotecas Gerais\n",
    "import numpy                   as np\n",
    "import pandas                  as pd\n",
    "import matplotlib.pyplot       as plt\n",
    "import seaborn                 as sns\n",
    "import sys\n",
    "import time\n",
    "from scipy                     import stats\n",
    "\n",
    "#Bibliotecas de Regressão\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.svm             import SVR\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.linear_model    import LinearRegression, Ridge, Lasso, LassoCV, ElasticNet, ElasticNetCV, HuberRegressor, LassoLars, BayesianRidge\n",
    "from sklearn.linear_model    import SGDRegressor\n",
    "from sklearn.ensemble        import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "# Bibliotecas de Clusterização\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster           import KMeans\n",
    "from sklearn.metrics           import silhouette_score, davies_bouldin_score,v_measure_score\n",
    "from sklearn.mixture           import GaussianMixture\n",
    "from sklearn.neural_network    import MLPRegressor\n",
    "from sklearn.metrics           import r2_score, mean_absolute_error,mean_squared_error\n",
    "from sklearn.model_selection   import GridSearchCV\n",
    "from sklearn.model_selection   import RandomizedSearchCV\n",
    "from sklearn.neighbors         import NearestNeighbors\n",
    "from sklearn.cluster           import DBSCAN\n",
    "from sklearn.cluster           import AgglomerativeClustering\n",
    "\n",
    "# Bibliotecas Classificação\n",
    "from sklearn                       import metrics\n",
    "from sklearn.preprocessing         import MinMaxScaler\n",
    "from sklearn.neighbors             import KNeighborsClassifier\n",
    "from sklearn.linear_model          import LogisticRegression\n",
    "from sklearn.tree                  import DecisionTreeClassifier\n",
    "from sklearn.ensemble              import RandomForestClassifier\n",
    "from sklearn.naive_bayes           import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.svm                   import SVC\n",
    "from sklearn.neural_network        import MLPClassifier\n",
    "from sklearn.metrics               import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.metrics               import classification_report\n",
    "from sklearn.metrics               import ConfusionMatrixDisplay\n",
    "from sklearn.metrics               import RocCurveDisplay\n",
    "\n",
    "# Bibliotecas de Recomendação\n",
    "from sklearn.metrics.pairwise      import cosine_similarity\n",
    "\n",
    "# Redução de Dimensionalidade\n",
    "from sklearn.decomposition         import PCA\n",
    "from sklearn.decomposition         import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packges Version Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1658,
     "status": "ok",
     "timestamp": 1739237531475,
     "user": {
      "displayName": "Felipe Silva",
      "userId": "04798968727763788783"
     },
     "user_tz": 180
    },
    "id": "GFxtDAUZm_Y4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze --local > ../requeriments.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101594,
     "status": "ok",
     "timestamp": 1739238310952,
     "user": {
      "displayName": "Felipe Silva",
      "userId": "04798968727763788783"
     },
     "user_tz": 180
    },
    "id": "oVGqMqLonq_I",
    "outputId": "2e212bae-8525-4297-d836-47ad204bab4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36837/2894423518.py:2: DtypeWarning:\n",
      "\n",
      "Columns (44,46,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link   = '../dados/dados_join.csv'\n",
    "df = pd.read_csv(link,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "link                  = '../dados/colnames.csv'\n",
    "colnames_dengue_bahia = pd.read_csv(link,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnamesbahia = colnames_dengue_bahia['nomes'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas que não temos em nosso dataset!\n",
      "NU_NOTIFIC\n",
      "ID_PESSOA\n",
      "NOME\n",
      "NOME DO MUNICÍPIO\n",
      "POPULAÇÃO ESTIMADA 2020\n",
      "POPULAÇÃO ESTIMADA 2019\n",
      "POPULAÇÃO ESTIMADA 2018\n",
      "POPULAÇÃO ESTIMADA 2017\n",
      "POPULAÇÃO ESTIMADA 2016\n",
      "POPULAÇÃO ESTIMADA 2015\n",
      "POPULAÇÃO ESTIMADA 2014\n",
      "POPULAÇÃO ESTIMADA 2013\n",
      "POPULAÇÃO ESTIMADA 2012\n",
      "POPULAÇÃO ESTIMADA 2011\n",
      "MUN_HOSP\n",
      "UF_HOSP\n",
      "MUN_SAUDENOT\n",
      "UF_SAUDENOT\n",
      "MUNI_RESI\n",
      "UF_RESI\n",
      "MUN_INFEC\n",
      "UF_INFEC\n",
      "IDADE\n",
      "SEM_PRI_V\n"
     ]
    }
   ],
   "source": [
    "print('Colunas que não temos em nosso dataset!')\n",
    "for column in colnamesbahia:\n",
    "    if(column not in df.columns): \n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/tmp/ipykernel_36837/301521693.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in colnamesbahia:\n",
    "\n",
    "    if(column in df.columns): \n",
    "        \n",
    "        df_new[column] = df[column].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Data Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Baseada no Trabalho Desenvolvido em: https://github.com/SarahSouzaPontes/analise_dados_dengue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CS_SEXO'].replace({'M': 'Masculino', 'F': 'Feminino', 'I': 'Sem Registro'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feminino' 'Masculino' 'Sem Registro']\n"
     ]
    }
   ],
   "source": [
    "print(df['CS_SEXO'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Raça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CS_RACA'].replace({\n",
    "    1: 'Branca',\n",
    "    2: 'Preta',\n",
    "    3: 'Amarela',\n",
    "    4: 'Parda',\n",
    "    5: 'Indígena',\n",
    "    6: 'Ignorado',\n",
    "    9: 'Sem Registro'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias únicas na coluna CS_RACA: ['Sem Registro' 'Branca' 'Preta' 'Parda' 'Amarela' 'Indígena']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Categorias únicas na coluna CS_RACA: {df['CS_RACA'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Sintomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA', 'VOMITO', 'NAUSEA', 'DOR_COSTAS',\n",
    "           'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA', 'PETEQUIA_N', 'LEUCOPENIA', 'LACO',\n",
    "           'DOR_RETRO', 'DIABETES', 'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA',\n",
    "           'ACIDO_PEPT', 'AUTO_IMUNE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36837/3739927340.py:2: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n",
      "/tmp/ipykernel_36837/3739927340.py:3: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for coluna in colunas:\n",
    "    df[coluna].fillna(0, inplace=True)\n",
    "    df[coluna].replace({1: 'Sim', 2: 'Não'}, inplace=True)\n",
    "    df[coluna].replace({0: 'Sem Registro'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias únicas na coluna FEBRE: ['Sim' 'Não' 'Sem Registro']\n",
      "Categorias únicas na coluna MIALGIA: ['Sim' 'Não' 'Sem Registro']\n",
      "Categorias únicas na coluna CEFALEIA: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna EXANTEMA: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna VOMITO: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna NAUSEA: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna DOR_COSTAS: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna CONJUNTVIT: ['Não' 'Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna ARTRITE: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna ARTRALGIA: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna PETEQUIA_N: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna LEUCOPENIA: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna LACO: ['Não' 'Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna DOR_RETRO: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna DIABETES: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna HEMATOLOG: ['Não' 'Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna HEPATOPAT: ['Não' 'Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna RENAL: ['Não' 'Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna HIPERTENSA: ['Não' 'Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna ACIDO_PEPT: ['Não' 'Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna AUTO_IMUNE: ['Não' 'Sem Registro' 'Sim']\n"
     ]
    }
   ],
   "source": [
    "# Verificar o resultado\n",
    "for coluna in colunas:\n",
    "    print(f\"Categorias únicas na coluna {coluna}: {df[coluna].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeamento = {\n",
    "    'RES_CHIKS1': {4: 'Chikungunya', 2: 'Negativo', 1: 'Positivo', pd.NA: 'Sem Registro'},\n",
    "    'RES_CHIKS2': {4: 'Chikungunya', 2: 'Negativo', pd.NA: 'Sem Registro'},\n",
    "    'RESUL_PRNT': {4: 'Sem Registro', 2: 'Negativo'},\n",
    "    'RESUL_SORO': {4: 'Sem Registro', 1: 'Positivo', 3: 'Inconclusivo', 2: 'Negativo'},\n",
    "    'RESUL_NS1': {pd.NA: 'Sem Registro', 4: 'Não realizado', 2: 'Negativo', 1: 'Positivo', 3: 'Inconclusivo'},\n",
    "    'RESUL_VI_N': {pd.NA: 'Sem Registro', 4: 'Não realizado', 2: 'Negativo', 1: 'Positivo', 3: 'Inconclusivo'},\n",
    "    'SOROTIPO': {pd.NA: 'Sem Registro', 4: 'DEN 4', 3: 'DEN 3', 2: 'DEN 2', 1: 'DEN 1'},\n",
    "    'HISTOPA_N': {pd.NA: 'Sem Registro', 4: 'Não realizado', 2: 'Negativo', 1: 'Positivo', 3: 'Inconclusivo'},\n",
    "    'IMUNOH_N': {pd.NA: 'Sem Registro', 4: 'Sem Registro', 3: 'Sem Registro', 2: 'Negativo', 1: 'Positivo'},\n",
    "    'HOSPITALIZ': {1: 'Hospitalizado', 2: 'Não hospitalizado', 9: 'Ignorado'},\n",
    "    'TPAUTOCTO': {2: 'Autóctone', pd.NA: 'Sem Registro', 1: 'Sem Registro', 3: 'Sem Registro'},\n",
    "    'COUFINF': {29: '29', pd.NA: 'Sem Registro', 31: '31', 35: '35', 53: '53', 17: '17', 52: '52', 26: '26'},\n",
    "    'COPAINF': {1: '1', pd.NA: 'Sem Registro'},\n",
    "    'CLASSIFIN': {8: 'Descartado', 1: '1', 5: '5', pd.NA: 'Sem Registro', 2: '2', 3: '3', 10: '10', 11: '11', 12: '12', 13: '13'},\n",
    "    'CRITERIO': {pd.NA: 'Sem Registro', 3: 'Em investigação', 2: 'Clínico', 1: 'Laboratório'},\n",
    "    'DOENCA_TRA': {2: 'Sim', pd.NA: 'Sem Registro', 9: 'Ignorado', 1: 'Não'},\n",
    "    'CLINC_CHIK': {pd.NA: 'Sem Registro', 1: 'Aguda', 2: 'Crônica'},\n",
    "    'EVOLUCAO': {pd.NA: 'Sem Registro', 1: 'cura', 9: 'ignorado', 3: 'óbito por outras causas', 4: 'óbito em investigação', 2: 'óbito pelo agravo'}\n",
    "}\n",
    "\n",
    "# Renomear as categorias\n",
    "df.replace(mapeamento, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias únicas na coluna RES_CHIKS1: [nan  4.  2.  3.  1.]\n",
      "Categorias únicas na coluna RES_CHIKS2: [nan  4.  2.  3.  1.]\n",
      "Categorias únicas na coluna RESUL_PRNT: [nan  4.  2.]\n",
      "Categorias únicas na coluna RESUL_SORO: [nan  4.  2.  1.  3.]\n",
      "Categorias únicas na coluna RESUL_NS1: [ 1.  4.  2. nan  3.]\n",
      "Categorias únicas na coluna RESUL_VI_N: [nan  4.  1.  2.  3.]\n",
      "Categorias únicas na coluna SOROTIPO: [nan  1.  2.  3.]\n",
      "Categorias únicas na coluna HISTOPA_N: [nan  4.  2.  3.  1.]\n",
      "Categorias únicas na coluna IMUNOH_N: [nan  4.  2.  3.  1.]\n",
      "Categorias únicas na coluna HOSPITALIZ: [ 2. nan  1.  9.]\n",
      "Categorias únicas na coluna TPAUTOCTO: [nan  1.  2.  3.]\n",
      "Categorias únicas na coluna COUFINF: [nan 27. 29. 35. 14. 53. 32. 52. 21. 31. 50. 51. 15. 42. 41. 33. 11. 43.\n",
      " 28. 23. 26. 12. 13. 16. 17. 22. 24. 25.]\n",
      "Categorias únicas na coluna CRITERIO: [ 1.  2. nan  3.]\n",
      "Categorias únicas na coluna DOENCA_TRA: [nan]\n",
      "Categorias únicas na coluna CLINC_CHIK: [nan  1.  2.]\n",
      "Categorias únicas na coluna EVOLUCAO: [ 1. nan  9.  3.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "# Verificar o resultado\n",
    "colunas = ['RES_CHIKS1','RES_CHIKS2','RESUL_PRNT','RESUL_SORO','RESUL_NS1','RESUL_VI_N','SOROTIPO','HISTOPA_N','IMUNOH_N',\n",
    "           'HOSPITALIZ','TPAUTOCTO','COUFINF','CRITERIO','DOENCA_TRA','CLINC_CHIK','EVOLUCAO']\n",
    "\n",
    "for coluna in colunas:\n",
    "    print(f\"Categorias únicas na coluna {coluna}: {df[coluna].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias únicas na coluna ALRM_HIPOT: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_PLAQ: ['Sem Registro' 'Sim' 'Não']\n",
      "Categorias únicas na coluna ALRM_VOM: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_SANG: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_HEMAT: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_ABDOM: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_LETAR: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_HEPAT: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna ALRM_LIQ: ['Sem Registro' 'Não' 'Sim']\n"
     ]
    }
   ],
   "source": [
    "# Selecionar as colunas que começam com 'ALRM'\n",
    "colunas_alrm = [coluna for coluna in df.columns if coluna.startswith('ALRM')]\n",
    "\n",
    "# Mapeamento para as colunas ALRM\n",
    "mapeamento_alrm = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    0: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "# Renomear as categorias para as colunas ALRM\n",
    "for coluna in colunas_alrm:\n",
    "    df[coluna] = df[coluna].replace(mapeamento_alrm)\n",
    "\n",
    "# Verificar o resultado\n",
    "for coluna in colunas_alrm:\n",
    "    print(f\"Categorias únicas na coluna {coluna}: {df[coluna].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias únicas na coluna GRAV_PULSO: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_CONV: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_ENCH: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_INSUF: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_TAQUI: ['Sem Registro' 'Sim' 'Não']\n",
      "Categorias únicas na coluna GRAV_EXTRE: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_HIPOT: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_HEMAT: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_MELEN: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_METRO: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_SANG: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_AST: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_MIOC: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_CONSC: ['Sem Registro' 'Não' 'Sim']\n",
      "Categorias únicas na coluna GRAV_ORGAO: ['Sem Registro' 'Não' 'Sim']\n"
     ]
    }
   ],
   "source": [
    "# Selecionar as colunas que começam com 'GRAV'\n",
    "colunas_grav = [coluna for coluna in df.columns if coluna.startswith('GRAV')]\n",
    "\n",
    "# Mapeamento para as colunas GRAV\n",
    "mapeamento_grav = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    0: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "# Renomear as categorias para as colunas GRAV\n",
    "for coluna in colunas_grav:\n",
    "    df[coluna] = df[coluna].replace(mapeamento_grav)\n",
    "\n",
    "# Verificar o resultado\n",
    "for coluna in colunas_grav:\n",
    "    print(f\"Categorias únicas na coluna {coluna}: {df[coluna].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias únicas na coluna MANI_HEMOR: ['Sem Registro']\n",
      "Categorias únicas na coluna EPISTAXE: ['Sem Registro']\n",
      "Categorias únicas na coluna GENGIVO: ['Sem Registro']\n",
      "Categorias únicas na coluna METRO: ['Sem Registro']\n",
      "Categorias únicas na coluna HEMATURA: ['Sem Registro']\n",
      "Categorias únicas na coluna SANGRAM: ['Sem Registro']\n",
      "Categorias únicas na coluna LACO_N: ['Sem Registro']\n",
      "Categorias únicas na coluna PLASMATICO: ['Sem Registro']\n",
      "Categorias únicas na coluna EVIDENCIA: ['Sem Registro']\n",
      "Categorias únicas na coluna CON_FHD: ['Sem Registro']\n",
      "Categorias únicas na coluna COMPLICA: ['Sem Registro']\n",
      "Categorias únicas na coluna TP_SISTEMA: ['Não' 'Sem Registro']\n",
      "Categorias únicas na coluna NDUPLIC_N: ['Sem Registro' 'Sim']\n",
      "Categorias únicas na coluna CS_FLXRET: ['Sim' 'Sem Registro']\n",
      "Categorias únicas na coluna FLXRECEBI: ['Sem Registro']\n"
     ]
    }
   ],
   "source": [
    "# Mapeamento Outras Colunas\n",
    "\n",
    "mapeamento_mani_hemor = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    0: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não',\n",
    "    9: 'Não Realizado'\n",
    "}\n",
    "\n",
    "mapeamento_epistaxe = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_gengivo = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_metro = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_petequias = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_hematuria = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_sangram = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_laco_n = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não',\n",
    "    9: 'Não Realizado'\n",
    "}\n",
    "\n",
    "mapeamento_plasmatico = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não',\n",
    "    9: 'Não Realizado'\n",
    "}\n",
    "\n",
    "mapeamento_evidencia = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não',\n",
    "    3: 'Indeterminado'\n",
    "}\n",
    "\n",
    "mapeamento_con_fhd = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_complica = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não',\n",
    "    3: 'Indeterminado'\n",
    "}\n",
    "\n",
    "mapeamento_tp_sistema = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_nduplic_n = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "mapeamento_cs_flxret = {\n",
    "    0: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não',\n",
    "    5: 'Sem Registro'\n",
    "}\n",
    "\n",
    "mapeamento_flxrecebi = {\n",
    "    np.nan: 'Sem Registro',\n",
    "    1: 'Sim',\n",
    "    2: 'Não'\n",
    "}\n",
    "\n",
    "# Aplicar o mapeamento para cada coluna\n",
    "df['MANI_HEMOR'] = df['MANI_HEMOR'].replace(mapeamento_mani_hemor)\n",
    "df['EPISTAXE'] = df['EPISTAXE'].replace(mapeamento_epistaxe)\n",
    "df['GENGIVO'] = df['GENGIVO'].replace(mapeamento_gengivo)\n",
    "df['METRO'] = df['METRO'].replace(mapeamento_metro)\n",
    "df['PETEQUIAS'] = df['PETEQUIAS'].replace(mapeamento_petequias)\n",
    "df['HEMATURA'] = df['HEMATURA'].replace(mapeamento_hematuria)\n",
    "df['SANGRAM'] = df['SANGRAM'].replace(mapeamento_sangram)\n",
    "df['LACO_N'] = df['LACO_N'].replace(mapeamento_laco_n)\n",
    "df['PLASMATICO'] = df['PLASMATICO'].replace(mapeamento_plasmatico)\n",
    "df['EVIDENCIA'] = df['EVIDENCIA'].replace(mapeamento_evidencia)\n",
    "df['CON_FHD'] = df['CON_FHD'].replace(mapeamento_con_fhd)\n",
    "df['COMPLICA'] = df['COMPLICA'].replace(mapeamento_complica)\n",
    "df['TP_SISTEMA'] = df['TP_SISTEMA'].replace(mapeamento_tp_sistema)\n",
    "df['NDUPLIC_N'] = df['NDUPLIC_N'].replace(mapeamento_nduplic_n)\n",
    "df['CS_FLXRET'] = df['CS_FLXRET'].replace(mapeamento_cs_flxret)\n",
    "df['FLXRECEBI'] = df['FLXRECEBI'].replace(mapeamento_flxrecebi)\n",
    "\n",
    "# Verificar o resultado\n",
    "print(\"Categorias únicas na coluna MANI_HEMOR:\", df['MANI_HEMOR'].unique())\n",
    "print(\"Categorias únicas na coluna EPISTAXE:\", df['EPISTAXE'].unique())\n",
    "print(\"Categorias únicas na coluna GENGIVO:\", df['GENGIVO'].unique())\n",
    "print(\"Categorias únicas na coluna METRO:\", df['METRO'].unique())\n",
    "print(\"Categorias únicas na coluna HEMATURA:\", df['HEMATURA'].unique())\n",
    "print(\"Categorias únicas na coluna SANGRAM:\", df['SANGRAM'].unique())\n",
    "print(\"Categorias únicas na coluna LACO_N:\", df['LACO_N'].unique())\n",
    "print(\"Categorias únicas na coluna PLASMATICO:\", df['PLASMATICO'].unique())\n",
    "print(\"Categorias únicas na coluna EVIDENCIA:\", df['EVIDENCIA'].unique())\n",
    "print(\"Categorias únicas na coluna CON_FHD:\", df['CON_FHD'].unique())\n",
    "print(\"Categorias únicas na coluna COMPLICA:\", df['COMPLICA'].unique())\n",
    "print(\"Categorias únicas na coluna TP_SISTEMA:\", df['TP_SISTEMA'].unique())\n",
    "print(\"Categorias únicas na coluna NDUPLIC_N:\", df['NDUPLIC_N'].unique())\n",
    "print(\"Categorias únicas na coluna CS_FLXRET:\", df['CS_FLXRET'].unique())\n",
    "print(\"Categorias únicas na coluna FLXRECEBI:\", df['FLXRECEBI'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variável                         Descrição\n",
      "0      COMUNINF         Comunicante da informação\n",
      "1    ID_MN_RESI     ID do município de residência\n",
      "2    ID_MUNICIP                   ID do município\n",
      "3     MUNICIPIO                         Município\n",
      "4        TP_NOT               Tipo de notificação\n",
      "..          ...                               ...\n",
      "114    COMPLICA    Descrição da variável COMPLICA\n",
      "115  TP_SISTEMA  Descrição da variável TP_SISTEMA\n",
      "116   NDUPLIC_N   Descrição da variável NDUPLIC_N\n",
      "117   CS_FLXRET   Descrição da variável CS_FLXRET\n",
      "118   FLXRECEBI   Descrição da variável FLXRECEBI\n",
      "\n",
      "[119 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dados das variáveis e suas descrições\n",
    "dados_variaveis = {\n",
    "    'COMUNINF': 'Comunicante da informação',\n",
    "    'ID_MN_RESI': 'ID do município de residência',\n",
    "    'ID_MUNICIP': 'ID do município',\n",
    "    'MUNICIPIO': 'Município',\n",
    "    'TP_NOT': 'Tipo de notificação',\n",
    "    'ID_AGRAVO': 'ID do agravo',\n",
    "    'DT_NOTIFIC': 'Data de notificação',\n",
    "    'SEM_NOT': 'Semana de notificação',\n",
    "    'NU_ANO': 'Ano da notificação',\n",
    "    'SG_UF_NOT': 'Sigla do estado da notificação',\n",
    "    'ID_REGIONA': 'ID da regional',\n",
    "    'ID_UNIDADE': 'ID da unidade',\n",
    "    'DT_SIN_PRI': 'Data do sinal/sintoma principal',\n",
    "    'SEM_PRI': 'Semana do sinal/sintoma principal',\n",
    "    'DT_NASC': 'Data de nascimento',\n",
    "    'NU_IDADE_N': 'Número da idade na notificação',\n",
    "    'CS_SEXO': 'Código do sexo',\n",
    "    'CS_GESTANT': 'Código de gestante',\n",
    "    'CS_RACA': 'Código da raça/cor',\n",
    "    'CS_ESCOL_N': 'Código de escolaridade',\n",
    "    'SG_UF': 'Sigla do estado',\n",
    "    'ID_RG_RESI': 'ID da região de residência',\n",
    "    'ID_PAIS': 'ID do país',\n",
    "    'DT_INVEST': 'Data do início do investimento',\n",
    "    'ID_OCUPA_N': 'ID da ocupação',\n",
    "    'FEBRE': 'Presença de febre',\n",
    "    'MIALGIA': 'Presença de mialgia',\n",
    "    'CEFALEIA': 'Presença de cefaleia',\n",
    "    'EXANTEMA': 'Presença de exantema',\n",
    "    'VOMITO': 'Presença de vômito',\n",
    "    'NAUSEA': 'Presença de náusea',\n",
    "    'DOR_COSTAS': 'Presença de dor nas costas',\n",
    "    'CONJUNTVIT': 'Presença de conjuntivite',\n",
    "    'ARTRITE': 'Presença de artrite',\n",
    "    'ARTRALGIA': 'Presença de artralgia',\n",
    "    'PETEQUIA_N': 'Presença de petéquias',\n",
    "    'LEUCOPENIA': 'Presença de leucopenia',\n",
    "    'LACO': 'Presença de laco',\n",
    "    'DOR_RETRO': 'Presença de dor retroocular',\n",
    "    'DIABETES': 'Presença de diabetes',\n",
    "    'HEMATOLOG': 'Presença de hematológico',\n",
    "    'HEPATOPAT': 'Presença de hepatopatia',\n",
    "    'RENAL': 'Presença de renal',\n",
    "    'HIPERTENSA': 'Presença de hipertensão',\n",
    "    'ACIDO_PEPT': 'Presença de acido peptico',\n",
    "    'AUTO_IMUNE': 'Presença de auto-imunidade',\n",
    "    'DT_CHIK_S1': 'Data de coleta da amostra para o exame CHIKV IgM',\n",
    "    'DT_CHIK_S2': 'Data de coleta da amostra para o exame CHIKV IgG',\n",
    "    'DT_PRNT': 'Data de coleta da amostra para o exame PRNT',\n",
    "    'RES_CHIKS1': 'Resultado do exame CHIKV IgM',\n",
    "    'RES_CHIKS2': 'Resultado do exame CHIKV IgG',\n",
    "    'RESUL_PRNT': 'Resultado do exame PRNT',\n",
    "    'DT_SORO': 'Data da coleta de soro',\n",
    "    'RESUL_SORO': 'Resultado do exame sorológico',\n",
    "    'DT_NS1': 'Data da coleta de NS1',\n",
    "    'RESUL_NS1': 'Resultado do exame NS1',\n",
    "    'DT_VIRAL': 'Data da coleta do exame de PCR',\n",
    "    'RESUL_VI_N': 'Resultado do exame de PCR',\n",
    "    'DT_PCR': 'Data da coleta do exame de PCR',\n",
    "    'RESUL_PCR_': 'Resultado do exame de PCR',\n",
    "    'SOROTIPO': 'Sorotipo',\n",
    "    'HISTOPA_N': 'Resultado do exame histopatológico',\n",
    "    'IMUNOH_N': 'Resultado do exame imunohistoquímico',\n",
    "    'HOSPITALIZ': 'Indicador de hospitalização',\n",
    "    'DT_INTERNA': 'Data de internação',\n",
    "    'UF': 'Estado do Brasil',\n",
    "    'TPAUTOCTO': 'Tipo de notificação autóctone',\n",
    "    'COUFINF': 'Código de confirmacão de infecção',\n",
    "    'COPAISINF': 'Código de país confirmado de infecção',\n",
    "    'CLASSI_FIN': 'Classificação final do caso',\n",
    "    'CRITERIO': 'Critério de confirmação',\n",
    "    'DOENCA_TRA': 'Doença relacionada ao trabalho',\n",
    "    'CLINC_CHIK': 'Clínica de Chikungunya',\n",
    "    'EVOLUCAO': 'Evolução do caso',\n",
    "    'DT_OBITO': 'Data de óbito',\n",
    "    'DT_ENCERRA': 'Data de encerramento',\n",
    "    'ALRM_HIPOT': 'Alarme de hipotensão',\n",
    "    'ALRM_PLAQ': 'Alarme de plaquetas',\n",
    "    'ALRM_VOM': 'Alarme de vômito',\n",
    "    'ALRM_SANG': 'Alarme de sangramento',\n",
    "    'ALRM_HEMAT': 'Alarme de hematoma',\n",
    "    'ALRM_ABDOM': 'Alarme de dor abdominal',\n",
    "    'ALRM_LETAR': 'Alarme de letargia',\n",
    "    'ALRM_HEPAT': 'Alarme de hepatomegalia',\n",
    "    'ALRM_LIQ': 'Alarme de derrame pleural',\n",
    "    'DT_ALRM': 'Data do alarme',\n",
    "    'GRAV_PULSO': 'Descrição da variável GRAV_PULSO',\n",
    "    'GRAV_CONV': 'Descrição da variável GRAV_CONV',\n",
    "    'GRAV_ENCH': 'Descrição da variável GRAV_ENCH',\n",
    "    'GRAV_INSUF': 'Descrição da variável GRAV_INSUF',\n",
    "    'GRAV_TAQUI': 'Descrição da variável GRAV_TAQUI',\n",
    "    'GRAV_EXTRE': 'Descrição da variável GRAV_EXTRE',\n",
    "    'GRAV_HIPOT': 'Descrição da variável GRAV_HIPOT',\n",
    "    'GRAV_HEMAT': 'Descrição da variável GRAV_HEMAT',\n",
    "    'GRAV_MELEN': 'Descrição da variável GRAV_MELEN',\n",
    "    'GRAV_METRO': 'Descrição da variável GRAV_METRO',\n",
    "    'GRAV_SANG': 'Descrição da variável GRAV_SANG',\n",
    "    'GRAV_AST': 'Descrição da variável GRAV_AST',\n",
    "    'GRAV_MIOC': 'Descrição da variável GRAV_MIOC',\n",
    "    'GRAV_CONSC': 'Descrição da variável GRAV_CONSC',\n",
    "    'GRAV_ORGAO': 'Descrição da variável GRAV_ORGAO',\n",
    "    'DT_GRAV': 'Descrição da variável DT_GRAV',\n",
    "    'MANI_HEMOR': 'Descrição da variável MANI_HEMOR',\n",
    "    'EPISTAXE': 'Descrição da variável EPISTAXE',\n",
    "    'GENGIVO': 'Descrição da variável GENGIVO',\n",
    "    'METRO': 'Descrição da variável METRO',\n",
    "    'PETEQUIAS': 'Descrição da variável PETEQUIAS',\n",
    "    'HEMATURA': 'Descrição da variável HEMATURA',\n",
    "    'SANGRAM': 'Descrição da variável SANGRAM',\n",
    "    'LACO_N': 'Descrição da variável LACO_N',\n",
    "    'PLASMATICO': 'Descrição da variável PLASMATICO',\n",
    "    'EVIDENCIA': 'Descrição da variável EVIDENCIA',\n",
    "    'PLAQ_MENOR': 'Descrição da variável PLAQ_MENOR',\n",
    "    'CON_FHD': 'Descrição da variável CON_FHD',\n",
    "    'COMPLICA': 'Descrição da variável COMPLICA',\n",
    "    'TP_SISTEMA': 'Descrição da variável TP_SISTEMA',\n",
    "    'NDUPLIC_N': 'Descrição da variável NDUPLIC_N',\n",
    "    'CS_FLXRET': 'Descrição da variável CS_FLXRET',\n",
    "    'FLXRECEBI': 'Descrição da variável FLXRECEBI',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados_variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame a partir do dicionário\n",
    "df_descricao_variaveis = pd.DataFrame(dados_variaveis.items(), columns=['Variável', 'Descrição'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variável                         Descrição\n",
      "0      COMUNINF         Comunicante da informação\n",
      "1    ID_MN_RESI     ID do município de residência\n",
      "2    ID_MUNICIP                   ID do município\n",
      "3     MUNICIPIO                         Município\n",
      "4        TP_NOT               Tipo de notificação\n",
      "..          ...                               ...\n",
      "114    COMPLICA    Descrição da variável COMPLICA\n",
      "115  TP_SISTEMA  Descrição da variável TP_SISTEMA\n",
      "116   NDUPLIC_N   Descrição da variável NDUPLIC_N\n",
      "117   CS_FLXRET   Descrição da variável CS_FLXRET\n",
      "118   FLXRECEBI   Descrição da variável FLXRECEBI\n",
      "\n",
      "[119 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exibir DataFrame\n",
    "print(df_descricao_variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36837/3476233426.py:3: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Sem Registro' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se df é o seu DataFrame\n",
    "# Substitua os valores NaN por 'Sem Registro'\n",
    "df.fillna('Sem Registro', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de mapeamento para os valores da coluna CS_ESCOL_N\n",
    "mapeamento_escolaridade = {\n",
    "    1: '1ª a 4ª série incompleta do EF',\n",
    "    2: '4ª série completa do EF (antigo 1° grau)',\n",
    "    3: '5ª à 8ª série incompleta do EF (antigo ginásio ou 1° grau)',\n",
    "    4: 'Ensino fundamental completo (antigo ginásio ou 1° grau)',\n",
    "    5: 'Ensino médio incompleto (antigo colegial ou 2° grau)',\n",
    "    6: 'Ensino médio completo (antigo colegial ou 2° grau)',\n",
    "    7: 'Educação superior incompleta',\n",
    "    8: 'Educação superior completa',\n",
    "    9: 'Ignorado',\n",
    "    10: 'Não se aplica'\n",
    "}\n",
    "\n",
    "# Substituir os valores na coluna CS_ESCOL_N usando o dicionário de mapeamento\n",
    "df['CS_ESCOL_N'] = df['CS_ESCOL_N'].replace(mapeamento_escolaridade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de mapeamento para os valores da coluna CS_GESTANT\n",
    "mapeamento_gestante = {\n",
    "    1: '1º Trimestre',\n",
    "    2: '2º Trimestre',\n",
    "    3: '3º Trimestre',\n",
    "    4: 'Idade gestacional ignorada',\n",
    "    5: 'Não',\n",
    "    6: 'Não se aplica',\n",
    "    9: 'Ignorado'\n",
    "}\n",
    "\n",
    "# Substituir os valores na coluna CS_GESTANT usando o dicionário de mapeamento\n",
    "df['CS_GESTANT'] = df['CS_GESTANT'].replace(mapeamento_gestante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ignorado', 'Ensino médio completo (antigo colegial ou 2° grau)',\n",
       "       '5ª à 8ª série incompleta do EF (antigo ginásio ou 1° grau)',\n",
       "       'Educação superior completa', 'Sem Registro',\n",
       "       '4ª série completa do EF (antigo 1° grau)',\n",
       "       'Ensino médio incompleto (antigo colegial ou 2° grau)',\n",
       "       'Não se aplica', '1ª a 4ª série incompleta do EF',\n",
       "       'Ensino fundamental completo (antigo ginásio ou 1° grau)',\n",
       "       'Educação superior incompleta', 0.0], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CS_ESCOL_N'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Não', 'Não se aplica', 'Ignorado', '2º Trimestre', '3º Trimestre',\n",
       "       '1º Trimestre', 'Idade gestacional ignorada', 'Sem Registro'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CS_GESTANT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando as variáveis fornecidas ao dicionário de renomeação e ao dicionário de tipos de dados\n",
    "\n",
    "# Dicionário de renomeação das colunas\n",
    "renomeacao_colunas = {\n",
    "    'SEM_NOT': 'Semana de notificação',\n",
    "    'NU_ANO': 'Ano da notificação',\n",
    "    'SG_UF_NOT': 'Sigla do estado da notificação',\n",
    "    'ID_REGIONA': 'ID da regional',\n",
    "    'ID_UNIDADE': 'ID da unidade',\n",
    "    'DT_SIN_PRI': 'Data do sinal/sintoma principal',\n",
    "    'SEM_PRI': 'Semana do sinal/sintoma principal',\n",
    "    'DT_NASC': 'Data de nascimento',\n",
    "    'NU_IDADE_N': 'Número da ID na notificação',\n",
    "    'CS_SEXO': 'Código do sexo',\n",
    "    'CS_GESTANT': 'Código de gestante',\n",
    "    'CS_RACA': 'Código da raça/cor',\n",
    "    'CS_ESCOL_N': 'Código de escolaridade',\n",
    "    'SG_UF': 'Sigla do estado',\n",
    "    'ID_RG_RESI': 'ID da região de residência',\n",
    "    'ID_PAIS': 'ID do país',\n",
    "    'DT_INVEST': 'Data do início da investigação',\n",
    "    'ID_OCUP': 'ID da ocupação',\n",
    "    'FEBRE': 'Presença de febre',\n",
    "    'MIALGIA': 'Presença de mialgia',\n",
    "    'CEFALEIA': 'Presença de cefaleia',\n",
    "    'EXANTEMA': 'Presença de exantema',\n",
    "    'VOMITO': 'Presença de vômito',\n",
    "    'NAUSEA': 'Presença de náusea',\n",
    "    'DOR_COSTAS': 'Presença de dor nas costas',\n",
    "    'CONJUNTVIT': 'Presença de conjuntivite',\n",
    "    'ARTRITE': 'Presença de artrite',\n",
    "    'ARTRALGIA': 'Presença de artralgia',\n",
    "    'PETEQUIA_N': 'Presença de petéquias',\n",
    "    'LEUCOPENIA': 'Presença de leucopenia',\n",
    "    'LACO': 'Presença de laço',\n",
    "    'DOR_RETRO': 'Presença de dor retroocular',\n",
    "    'DIABETES': 'Presença de diabetes',\n",
    "    'HEMATOLOG': 'Presença de hematológico',\n",
    "    'HEPATOPAT': 'Presença de hepatopatia',\n",
    "    'RENAL': 'Presença de renal',\n",
    "    'HIPERTENSA': 'Presença de hipertensão',\n",
    "    'ACIDO_PEPT': 'Presença de ácido péptico',\n",
    "    'AUTO_IMUNE': 'Presença de autoimunidade',\n",
    "    'DT_CHIK_S1': 'Data de coleta da amostra para o exame CHIKV IgM',\n",
    "    'DT_CHIK_S2': 'Data de coleta da amostra para o exame CHIKV IgG',\n",
    "    'DT_PRNT': 'Data de coleta da amostra para o exame PRNT',\n",
    "    'RES_CHIKS1': 'Resultado do exame CHIKV IgM',\n",
    "    'RES_CHIKS2': 'Resultado do exame CHIKV IgG',\n",
    "    'RESUL_PRNT': 'Resultado do exame PRNT',\n",
    "    'DT_SORO': 'Data da coleta de soro',\n",
    "    'RESUL_SORO': 'Resultado do exame sorológico',\n",
    "    'DT_NS1': 'Data da coleta de NS1',\n",
    "    'RESUL_NS1': 'Resultado do exame NS1',\n",
    "    'DT_VIRAL': 'Data da coleta do exame de PCR',\n",
    "    'RESUL_VI_N': 'Resultado do exame de PCR',\n",
    "    'DT_PCR': 'Data da coleta do exame de PCR',\n",
    "    'RESUL_PCR_': 'Resultado do exame de PCR',\n",
    "    'SOROTIPO': 'Sorotipo',\n",
    "    'HISTOPA_N': 'Resultado do exame histopatológico',\n",
    "    'IMUNOH_N': 'Resultado do exame imunohistoquímico',\n",
    "    'HOSPITALIZ': 'Indicador de hospitalização',\n",
    "    'DT_INTERNA': 'Data de internação',\n",
    "    'UF_INFEC': 'Estado do Brasil',\n",
    "    'TPAUTOCTO': 'Tipo de notificação autóctone',\n",
    "    'COUFINF': 'Código de confirmação de infecção',\n",
    "    'COPAISINF': 'Código de país confirmado de infecção',\n",
    "    'CLASSI_FIN': 'Classificação final do caso',\n",
    "    'CRITERIO': 'Critério de confirmação',\n",
    "    'DOENCA_TRA': 'Doença relacionada ao trabalho',\n",
    "    'CLINC_CHIK': 'Clínica de Chikungunya',\n",
    "    'EVOLUCAO': 'Evolução do caso',\n",
    "    'DT_OBITO': 'Data de óbito',\n",
    "    'DT_ENCERRA': 'Data de encerramento',\n",
    "    'ALRM_HIPOT': 'Alarme de hipotensão',\n",
    "    'ALRM_PLAQ': 'Alarme de plaquetas',\n",
    "    'ALRM_VOM': 'Alarme de vômito',\n",
    "    'ALRM_SANG': 'Alarme de sangramento',\n",
    "    'ALRM_HEMAT': 'Alarme de hematoma',\n",
    "    'GRAV_MIOC': 'Gravidade de miocárdio',\n",
    "    'GRAV_CONSC': 'Gravidade de nível de consciência',\n",
    "    'GRAV_ORGAO': 'Gravidade de órgão',\n",
    "    'DT_GRAV': 'Data da Gravidade',\n",
    "    'MANI_HEMOR': 'Manifestação de hemorragia',\n",
    "    'EPISTAXE': 'Manifestação de epistaxe',\n",
    "    'GENGIVO': 'Manifestação na gengiva',\n",
    "    'METRO': 'Manifestação de metrorragia',\n",
    "    'PETEQUIAS': 'Manifestação de petéquias',\n",
    "    'HEMATURA': 'Manifestação de hematúria',\n",
    "    'SANGRAM': 'Manifestação de sangramento',\n",
    "    'LACO_N': 'Presença de laço',\n",
    "    'PLASMATICO': 'Relacionado ao plasma',\n",
    "    'EVIDENCIA': 'Evidência médica',\n",
    "    'PLAQ_MENOR': 'Menor contagem de plaquetas',\n",
    "    'CON_FHD': 'Hipertensão Familiar',\n",
    "    'COMPLICA': 'Presença de complicações',\n",
    "    'TP_SISTEMA': 'Tipo de sistema',\n",
    "    'NDUPLIC_N': 'Reincidência do quadro',\n",
    "    'CS_FLXRET': 'Fluxo de retorno',\n",
    "    'FLXRECEBI': 'Fluxo de retorno recebido',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(renomeacao_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TP_NOT', 'ID_AGRAVO', 'DT_NOTIFIC', 'Semana de notificação',\n",
      "       'Ano da notificação', 'Sigla do estado da notificação', 'ID_MUNICIP',\n",
      "       'ID da regional', 'ID da unidade', 'Data do sinal/sintoma principal',\n",
      "       ...\n",
      "       'Presença de laço', 'Relacionado ao plasma', 'Evidência médica',\n",
      "       'Menor contagem de plaquetas', 'Hipertensão Familiar',\n",
      "       'Presença de complicações', 'Tipo de sistema', 'Reincidência do quadro',\n",
      "       'Fluxo de retorno', 'Fluxo de retorno recebido'],\n",
      "      dtype='object', length=119)\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a renomeação das colunas\n",
    "df2 = df.rename(columns=renomeacao_colunas)\n",
    "\n",
    "# Verificando as colunas renomeadas\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Hyperparamerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 ML Models and Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPGDooIhM2rQta2Rk8x0YbZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
